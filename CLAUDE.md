# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**bmad-assist** is a Python CLI tool that automates the BMAD development loop: create story â†’ validate â†’ develop â†’ code review â†’ retrospective. It orchestrates multiple LLM CLI tools (Claude Code, Gemini CLI, Codex, OpenCode, Amp, Copilot, Cursor, Kimi) with a Master/Multi/Guardian architecture.

**ğŸš« NEVER run `git push` without explicit user command!** Do not push to any remote repository unless the user explicitly tells you to push. This applies to both repos (bmad-assist-22 and bmad-assist). Commits are fine, push is forbidden without direct instruction.

**Development Workflow:** See `WORKTREE.md` for git worktree-based isolated development.

## Publishing to bmad-assist (GitHub)

This repo (bmad-assist-22) is the development environment. The publication repo is `../bmad-assist/`.

**Directory mapping:**
- `docs/` â†’ Internal BMAD docs (PRD, architecture, epics) - NOT published
- `docs-public/` â†’ User-facing docs â†’ synced to `bmad-assist/docs/`
- `README.md` â†’ Same in both repos, links to `docs/` work in publication

**Sync workflow (ALWAYS use this pattern):**
```bash
# 1. Sync code
rsync -av --delete --exclude='__pycache__' src/ ../bmad-assist/src/
rsync -av --delete --exclude='__pycache__' tests/ ../bmad-assist/tests/

# 2. Sync public docs
rsync -av --delete docs-public/ ../bmad-assist/docs/

# 3. Copy root files
cp README.md CHANGELOG.md bmad-assist.yaml pyproject.toml ../bmad-assist/

# 4. Verify tests pass in bmad-assist
cd ../bmad-assist && ../.venv/bin/pytest -q --tb=line --no-header

# 5. Commit and push (ASK USER FIRST!)
```

**IMPORTANT:** Always run tests in bmad-assist before committing there.

## Current Status (2026-01-31)

- **Completed:** Epics 1-4, 6, 7, 10-16, 18, 22-25 (TEA Enterprise Full Integration, 140+ stories)
- **In Progress:** Test refactoring, CI/CD setup
- **Recent:** Epic 25 - TEA Enterprise v7.0.0+ integration with 8 workflows, evidence collection, engagement models
- **Recent Refactors:** Config package modularization, Loop handler architecture, Notifications system, Strategic context optimization
- **Phase 2 Backlog:** Epics 5, 8, 9 (Power-Prompts, Guardian, Static Reports)

## Project Structure

Single repo architecture using **BMAD v6.0.0-alpha.22**:

### CLI Development (bmad-assist-22/):

```
bmad-assist-22/
â”œâ”€â”€ src/bmad_assist/           # CLI source code (EDIT HERE)
â”‚   â”œâ”€â”€ cli.py                 # Typer CLI entry point
â”‚   â”œâ”€â”€ commands/              # CLI command groups (modularized)
â”‚   â”œâ”€â”€ core/                  # Core: config/, loop/, state, paths
â”‚   â”œâ”€â”€ providers/             # LLM provider adapters (12 providers)
â”‚   â”œâ”€â”€ compiler/              # BMAD workflow compiler + patching
â”‚   â”œâ”€â”€ validation/            # Multi-LLM validation orchestration
â”‚   â”œâ”€â”€ code_review/           # Code review orchestration
â”‚   â”œâ”€â”€ benchmarking/          # LLM performance tracking + reports
â”‚   â”œâ”€â”€ testarch/              # Test Architect module
â”‚   â”œâ”€â”€ dashboard/             # Real-time dashboard UI + API
â”‚   â”œâ”€â”€ experiments/           # Experiment framework
â”‚   â”œâ”€â”€ notifications/         # Discord/Telegram notifications
â”‚   â”œâ”€â”€ sprint/                # Sprint status management
â”‚   â”œâ”€â”€ git/                   # Git operations (diff, branch, commit)
â”‚   â”œâ”€â”€ antipatterns/          # Antipattern extraction from reviews
â”‚   â”œâ”€â”€ qa/                    # QA plan generation & execution
â”‚   â”œâ”€â”€ retrospective/         # Epic retrospective reports
â”‚   â””â”€â”€ bmad/                  # BMAD file parsing + sharding
â”œâ”€â”€ docs/                      # Internal BMAD docs (PRD, architecture, epics)
â”œâ”€â”€ docs-public/               # User docs â†’ synced to bmad-assist/docs/
â”œâ”€â”€ experiments/               # Benchmark fixtures, analysis, runs
â”œâ”€â”€ .venv/                     # Single venv (Python 3.11 + pip)
â”œâ”€â”€ tests/                     # Test suite (~7000 tests)
â”œâ”€â”€ CLAUDE.md                  # This file
â””â”€â”€ WORKTREE.md                # Git worktree workflow guide
```

### For Target Projects (where BMAD generates code):

```
<target-project>/
â”œâ”€â”€ _bmad/                     # BMAD installation
â”‚   â””â”€â”€ bmm/
â”‚       â””â”€â”€ config.yaml        # Module configuration
â”œâ”€â”€ _bmad-output/              # Generated artifacts (gitignored)
â”‚   â”œâ”€â”€ planning-artifacts/    # PRD, architecture, epics
â”‚   â””â”€â”€ implementation-artifacts/
â”‚       â”œâ”€â”€ sprint-status.yaml # Sprint tracking
â”‚       â”œâ”€â”€ stories/           # Story files
â”‚       â”œâ”€â”€ code-reviews/      # Code review reports
â”‚       â”œâ”€â”€ story-validations/ # Validation reports
â”‚       â”œâ”€â”€ retrospectives/    # Epic retrospectives
â”‚       â””â”€â”€ benchmarks/        # LLM performance metrics
â”œâ”€â”€ docs/                      # Project knowledge
â”‚   â”œâ”€â”€ prd.md                 # Product Requirements
â”‚   â”œâ”€â”€ architecture.md        # Architectural decisions
â”‚   â”œâ”€â”€ project-context.md     # AI agent rules
â”‚   â”œâ”€â”€ epics/                 # Epic definitions (sharded)
â”‚   â””â”€â”€ modules/               # Module documentation
â””â”€â”€ .bmad-assist/              # Project-specific patches
    â”œâ”€â”€ patches/               # Workflow patches
    â””â”€â”€ cache/                 # Template cache
```

**Key Paths from Config:**
- `planning_artifacts`: `_bmad-output/planning-artifacts/`
- `implementation_artifacts`: `_bmad-output/implementation-artifacts/`
- `project_knowledge`: `docs/`

## Build & Development Commands

**IMPORTANT: Always run Python commands through the virtual environment (`.venv`).** Activate it first with `source .venv/bin/activate` or prefix commands with `.venv/bin/` (e.g., `.venv/bin/pytest`, `.venv/bin/python`).

```bash
# Install in development mode
pip install -e .

# Run CLI
bmad-assist run --project ./my-project

# Compile workflow to standalone prompt
bmad-assist compile -w create-story -e 11 -s 1

# Experiment framework commands
bmad-assist experiment run -f minimal -c opus-solo -P baseline -l standard
bmad-assist experiment batch --fixtures minimal,complex --configs opus-solo,haiku-solo -P baseline -l standard
bmad-assist experiment list [--status completed] [--fixture minimal]
bmad-assist experiment show run-2026-01-09-001
bmad-assist experiment compare run-001 run-002 --output comparison.md
bmad-assist experiment templates [--type config|loop|patch-set|fixture]

# Dashboard
bmad-assist serve --project ./my-project --port 8080

# TEA Standalone Workflows
bmad-assist tea framework [-r PROJECT] [-m create|validate|edit] [-d]
bmad-assist tea ci [-r PROJECT] [--ci-platform github|gitlab|circleci] [-d]
bmad-assist tea test-design [-r PROJECT] [--level system|epic] [-d]
bmad-assist tea automate [-r PROJECT] [--component COMPONENT] [-d]
bmad-assist tea nfr-assess [-r PROJECT] [--category CATEGORY] [-d]

# Quality scorecard (experiment fixtures)
bmad-assist test scorecard <fixture-name>

# Run tests (token-optimized - ALWAYS use these flags)
pytest -q --tb=line --no-header
pytest -q --tb=line --no-header tests/core/test_state.py   # Single file
pytest -q --tb=line --no-header -k "test_atomic_write"     # By pattern
```

**âš ï¸ TEST STRATEGY - IMPORTANT:**
- **DO NOT run full test suite (`pytest tests/`)** unless absolutely necessary
- Full suite takes ~90-120 seconds - too slow for iterative development
- **During development**: Run only relevant test files or patterns
- **Before commit**: Run `mypy src/` and `ruff check src/` (fast)
- **Only at the END of implementation** (before PR/push): Run full test suite once to verify

```bash
# Type checking
mypy src/

# Linting
ruff check src/
ruff format src/
```

### Frontend Development

Dashboard UI uses a modular build system - **NEVER edit `static/index.html` directly!**

**Build System Structure:**
```
src/bmad_assist/dashboard/
â”œâ”€â”€ static-src/              # SOURCE files (edit here!)
â”‚   â”œâ”€â”€ 01-head.html        # DOCTYPE, meta, CDN links (Tailwind, Basecoat, Alpine, HTMX)
â”‚   â”œâ”€â”€ 02-sidebar.html     # Project tree navigation
â”‚   â”œâ”€â”€ 03-main-header.html # Top bar controls
â”‚   â”œâ”€â”€ 04-terminal.html    # Terminal output section
â”‚   â”œâ”€â”€ 05-settings-panel.html   # Settings configuration
â”‚   â”œâ”€â”€ 06-experiments-panel.html # Experiment list
â”‚   â”œâ”€â”€ 07-experiment-details.html # Experiment detail modal
â”‚   â”œâ”€â”€ 08-comparison-panel.html   # Run comparison
â”‚   â”œâ”€â”€ 09-footer.html      # Bottom controls
â”‚   â”œâ”€â”€ 10-modals.html      # Context menu, toasts, busy modal
â”‚   â””â”€â”€ 11-tail.html        # Alpine.js dashboard() component, scripts
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html          # GENERATED output (DO NOT EDIT!)
â”œâ”€â”€ build_static.py         # Concat partials â†’ index.html
â””â”€â”€ split_index.py          # Split index.html â†’ partials (one-time setup)
```

**Build Commands:**
```bash
# One-time build (generates static/index.html from static-src/*.html)
python src/bmad_assist/dashboard/build_static.py

# Watch mode (auto-rebuild on static-src/ changes)
python src/bmad_assist/dashboard/build_static.py --watch
```

**Key Rules:**
- Edit files in `static-src/`, NEVER `static/index.html`
- Partials are concatenated in numeric order (01-11)
- Build process overwrites `static/index.html` completely
- Use watch mode during active frontend development

## Architecture

### Core Components

```
src/bmad_assist/
â”œâ”€â”€ cli.py                 # Typer CLI entry point (core commands only)
â”œâ”€â”€ cli_utils.py           # Shared CLI utilities (EXIT_*, console, helpers)
â”œâ”€â”€ commands/              # CLI command groups (modularized)
â”‚   â”œâ”€â”€ benchmark.py       # bmad-assist benchmark compare/models
â”‚   â”œâ”€â”€ compile.py         # bmad-assist compile workflow
â”‚   â”œâ”€â”€ experiment.py      # bmad-assist experiment run/batch/list/show/compare
â”‚   â”œâ”€â”€ init.py            # bmad-assist init project setup
â”‚   â”œâ”€â”€ patch.py           # bmad-assist patch compile/list
â”‚   â”œâ”€â”€ qa.py              # bmad-assist qa generate/execute
â”‚   â”œâ”€â”€ serve.py           # bmad-assist serve dashboard
â”‚   â”œâ”€â”€ sprint.py          # bmad-assist sprint generate/repair/validate/sync
â”‚   â””â”€â”€ test.py            # bmad-assist test scorecard
â”‚
â”œâ”€â”€ core/                  # Core package (refactored 2026-01)
â”‚   â”œâ”€â”€ config/            # Configuration subsystem
â”‚   â”‚   â”œâ”€â”€ loaders.py     # Config file loading + merging
â”‚   â”‚   â”œâ”€â”€ env.py         # Environment variable handling
â”‚   â”‚   â”œâ”€â”€ constants.py   # Config constants and defaults
â”‚   â”‚   â”œâ”€â”€ loop_config.py # LoopConfig loader
â”‚   â”‚   â”œâ”€â”€ schema.py      # Config validation schema
â”‚   â”‚   â””â”€â”€ models/        # Pydantic config models
â”‚   â”‚       â”œâ”€â”€ main.py    # BmadAssistConfig root model
â”‚   â”‚       â”œâ”€â”€ providers.py   # Provider configs (Master, Multi)
â”‚   â”‚       â”œâ”€â”€ paths.py       # PathsConfig model
â”‚   â”‚       â”œâ”€â”€ loop.py        # LoopConfig model
â”‚   â”‚       â”œâ”€â”€ features.py    # FeatureFlags model
â”‚   â”‚       â”œâ”€â”€ strategic_context.py  # Strategic context config
â”‚   â”‚       â””â”€â”€ source_context.py     # Source context config
â”‚   â”œâ”€â”€ loop/              # Development loop orchestration
â”‚   â”‚   â”œâ”€â”€ runner.py      # Main loop runner
â”‚   â”‚   â”œâ”€â”€ dispatch.py    # Phase dispatcher
â”‚   â”‚   â”œâ”€â”€ handlers/      # Phase handlers (one per workflow)
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py              # BaseHandler ABC
â”‚   â”‚   â”‚   â”œâ”€â”€ create_story.py      # Story creation
â”‚   â”‚   â”‚   â”œâ”€â”€ validate_story.py    # Multi-LLM validation
â”‚   â”‚   â”‚   â”œâ”€â”€ validate_story_synthesis.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dev_story.py         # Implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ code_review.py       # Multi-LLM review
â”‚   â”‚   â”‚   â”œâ”€â”€ code_review_synthesis.py
â”‚   â”‚   â”‚   â”œâ”€â”€ retrospective.py     # Epic retrospective
â”‚   â”‚   â”‚   â”œâ”€â”€ qa_plan_generate.py  # QA planning
â”‚   â”‚   â”‚   â””â”€â”€ qa_plan_execute.py   # QA execution
â”‚   â”‚   â”œâ”€â”€ epic_phases.py     # Epic-level phase logic
â”‚   â”‚   â”œâ”€â”€ epic_transitions.py # Epic state transitions
â”‚   â”‚   â”œâ”€â”€ story_transitions.py # Story state transitions
â”‚   â”‚   â”œâ”€â”€ sprint_sync.py     # Sprint status sync
â”‚   â”‚   â”œâ”€â”€ locking.py         # Process locking
â”‚   â”‚   â”œâ”€â”€ pause.py           # Pause/resume logic
â”‚   â”‚   â”œâ”€â”€ signals.py         # Signal handling
â”‚   â”‚   â”œâ”€â”€ notifications.py   # Event notifications
â”‚   â”‚   â”œâ”€â”€ dashboard_events.py # Dashboard SSE events
â”‚   â”‚   â””â”€â”€ types.py           # Loop type definitions
â”‚   â”œâ”€â”€ state.py           # YAML state persistence (atomic writes)
â”‚   â”œâ”€â”€ paths.py           # Project paths singleton
â”‚   â”œâ”€â”€ types.py           # EpicId type (int | str)
â”‚   â”œâ”€â”€ exceptions.py      # Custom exception hierarchy
â”‚   â”œâ”€â”€ timing.py          # Execution timing utilities
â”‚   â”œâ”€â”€ debug_logger.py    # JSON debug logging
â”‚   â”œâ”€â”€ extraction.py      # Output extraction helpers
â”‚   â”œâ”€â”€ config_editor.py   # Runtime config editing
â”‚   â””â”€â”€ config_generator.py # Config file generation
â”‚
â”œâ”€â”€ providers/             # LLM Provider Adapters
â”‚   â”œâ”€â”€ base.py            # BaseProvider ABC
â”‚   â”œâ”€â”€ registry.py        # Dynamic provider loading
â”‚   â”œâ”€â”€ claude.py          # Claude subprocess (--print)
â”‚   â”œâ”€â”€ claude_sdk.py      # Claude SDK (primary)
â”‚   â”œâ”€â”€ gemini.py          # Gemini CLI
â”‚   â”œâ”€â”€ codex.py           # OpenAI Codex
â”‚   â”œâ”€â”€ opencode.py        # OpenCode CLI
â”‚   â”œâ”€â”€ amp.py             # Amp CLI
â”‚   â”œâ”€â”€ copilot.py         # GitHub Copilot
â”‚   â”œâ”€â”€ cursor_agent.py    # Cursor Agent
â”‚   â””â”€â”€ kimi.py            # Kimi CLI (MoonshotAI)
â”‚
â”œâ”€â”€ compiler/              # BMAD Workflow Compiler
â”‚   â”œâ”€â”€ core.py            # compile_workflow() entry point
â”‚   â”œâ”€â”€ output.py          # XML output generator
â”‚   â”œâ”€â”€ variables/         # Variable resolution
â”‚   â”œâ”€â”€ patching/          # Patch system
â”‚   â”‚   â”œâ”€â”€ compiler.py    # Patch compilation
â”‚   â”‚   â”œâ”€â”€ discovery.py   # Patch discovery (project â†’ CWD â†’ global)
â”‚   â”‚   â””â”€â”€ cache.py       # Template cache
â”‚   â””â”€â”€ workflows/         # Workflow-specific compilers
â”‚
â”œâ”€â”€ validation/            # Multi-LLM Validation
â”‚   â”œâ”€â”€ orchestrator.py    # Parallel validation
â”‚   â”œâ”€â”€ anonymizer.py      # Output anonymization
â”‚   â””â”€â”€ reports.py         # Report extraction
â”‚
â”œâ”€â”€ code_review/           # Code Review
â”‚   â””â”€â”€ orchestrator.py    # Parallel review orchestration
â”‚
â”œâ”€â”€ benchmarking/          # LLM Performance Tracking
â”‚   â”œâ”€â”€ schema.py          # Metrics models
â”‚   â”œâ”€â”€ collector.py       # Deterministic metrics
â”‚   â”œâ”€â”€ extraction.py      # LLM-based extraction
â”‚   â”œâ”€â”€ storage.py         # YAML persistence
â”‚   â”œâ”€â”€ reports.py         # Comparison reports
â”‚   â””â”€â”€ prompts/           # Extraction prompts
â”‚
â”œâ”€â”€ dashboard/             # Real-time Dashboard
â”‚   â”œâ”€â”€ server.py          # Starlette + Uvicorn
â”‚   â”œâ”€â”€ routes/            # REST API (modularized)
â”‚   â”‚   â”œâ”€â”€ loop.py, status.py, content.py, sse.py
â”‚   â”‚   â”œâ”€â”€ config/        # Config CRUD
â”‚   â”‚   â””â”€â”€ experiments/   # Experiment API
â”‚   â”œâ”€â”€ sse.py             # SSE broadcaster
â”‚   â”œâ”€â”€ queue.py           # Task queue
â”‚   â”œâ”€â”€ static/            # Generated frontend
â”‚   â””â”€â”€ static-src/        # Source partials (01-11)
â”‚
â”œâ”€â”€ experiments/           # Experiment Framework
â”‚   â”œâ”€â”€ runner.py          # Experiment orchestration
â”‚   â”œâ”€â”€ fixture.py         # Fixture registry
â”‚   â”œâ”€â”€ config.py, loop.py, patchset.py  # Templates
â”‚   â”œâ”€â”€ isolation.py       # Fixture isolation
â”‚   â”œâ”€â”€ comparison.py      # Run comparison
â”‚   â””â”€â”€ scorecard.py       # Quality scorecard
â”‚
â”œâ”€â”€ notifications/         # Notification System (NEW)
â”‚   â”œâ”€â”€ dispatcher.py      # Event dispatcher
â”‚   â”œâ”€â”€ events.py          # Event definitions
â”‚   â”œâ”€â”€ formatter.py       # Message formatting
â”‚   â”œâ”€â”€ discord.py         # Discord webhook
â”‚   â””â”€â”€ telegram.py        # Telegram bot
â”‚
â”œâ”€â”€ sprint/                # Sprint Management (NEW)
â”‚   â”œâ”€â”€ generator.py       # Sprint status generation
â”‚   â”œâ”€â”€ parser.py          # Status file parsing
â”‚   â”œâ”€â”€ sync.py            # Story sync with sprint
â”‚   â”œâ”€â”€ repair.py          # Status repair
â”‚   â””â”€â”€ models.py          # Sprint models
â”‚
â”œâ”€â”€ git/                   # Git Operations (NEW)
â”‚   â”œâ”€â”€ diff.py            # Git diff generation
â”‚   â”œâ”€â”€ branch.py          # Branch management
â”‚   â”œâ”€â”€ committer.py       # Auto-commit logic
â”‚   â””â”€â”€ gitignore.py       # Gitignore handling
â”‚
â”œâ”€â”€ antipatterns/          # Antipattern Extraction (NEW)
â”‚   â”œâ”€â”€ extractor.py       # Extract from code reviews
â”‚   â””â”€â”€ prompts.py         # Extraction prompts
â”‚
â”œâ”€â”€ qa/                    # QA System
â”‚   â”œâ”€â”€ generator.py       # Test plan generation
â”‚   â”œâ”€â”€ executor.py        # Plan execution
â”‚   â”œâ”€â”€ playwright_executor.py  # Playwright tests
â”‚   â””â”€â”€ summary.py         # Results summary
â”‚
â”œâ”€â”€ retrospective/         # Epic Retrospectives
â”‚   â””â”€â”€ reports.py         # Retrospective generation
â”‚
â”œâ”€â”€ testarch/              # Test Architect Module (TEA Enterprise v7.0.0+)
â”‚   â”œâ”€â”€ config.py          # TestarchConfig model
â”‚   â”œâ”€â”€ eligibility.py     # ATDD eligibility detection
â”‚   â”œâ”€â”€ preflight.py       # Preflight infrastructure checks
â”‚   â”œâ”€â”€ engagement.py      # Engagement model logic (off/lite/solo/integrated/auto)
â”‚   â”œâ”€â”€ core/              # Core TEA infrastructure
â”‚   â”‚   â”œâ”€â”€ extraction.py  # Output extraction patterns
â”‚   â”‚   â”œâ”€â”€ types.py       # CIPlatform, ReviewScope enums
â”‚   â”‚   â””â”€â”€ variables.py   # TEAVariableResolver
â”‚   â”œâ”€â”€ handlers/          # TEA phase handlers (9 total: 1 base + 8 workflows)
â”‚   â”‚   â”œâ”€â”€ base.py        # TestarchBaseHandler ABC
â”‚   â”‚   â”œâ”€â”€ atdd.py, automate.py, ci.py, framework.py
â”‚   â”‚   â”œâ”€â”€ nfr_assess.py, test_design.py, test_review.py, trace.py
â”‚   â”œâ”€â”€ evidence/          # Evidence collection
â”‚   â”‚   â”œâ”€â”€ collector.py   # EvidenceContextCollector
â”‚   â”‚   â””â”€â”€ sources/       # coverage, test_results, security, performance
â”‚   â”œâ”€â”€ knowledge/         # Knowledge base loading
â”‚   â”‚   â”œâ”€â”€ loader.py      # KnowledgeBaseLoader
â”‚   â”‚   â””â”€â”€ index.py       # tea-index.csv parser
â”‚   â””â”€â”€ standalone/        # Standalone runner & CLI
â”‚       â”œâ”€â”€ runner.py      # StandaloneRunner
â”‚       â””â”€â”€ cli.py         # CLI commands (tea_app)
â”‚
â”œâ”€â”€ bmad/                  # BMAD File Parsing
â”‚   â”œâ”€â”€ parser.py          # Frontmatter + markdown
â”‚   â”œâ”€â”€ sharding/          # Sharded docs support
â”‚   â””â”€â”€ state_reader.py    # Project state reading
â”‚
â”œâ”€â”€ guardian/              # Anomaly Detection (Phase 2)
â”œâ”€â”€ prompts/               # Power-prompts (Phase 2)
â””â”€â”€ reporting/             # Static Reports (Phase 2)
```

### Project Patches

Workflow patches live in `.bmad-assist/patches/`:
- `defaults.yaml` - shared post_process rules
- `create-story.patch.yaml` - create-story transforms
- `validate-create-story.patch.yaml` - validation transforms
- `dev-story.patch.yaml` - dev-story transforms
- `code-review.patch.yaml` - code review transforms

**Centralized Patch Discovery** (in `compiler/core.py` via `compiler/patching/compiler.py`):
1. Before compiling, check for cached template: project â†’ CWD â†’ global
2. If no valid cache, look for patch: project â†’ CWD â†’ global
3. If patch exists, auto-compile it to cache
4. Load `workflow_ir` from cache or original files
5. Set `context.workflow_ir` and `context.patch_path` before calling compiler

### Key Design Patterns

**Provider Pattern**: All CLI tools implement `BaseProvider` ABC with `invoke()`, `parse_output()`, `supports_model()`.

**Config Package**: Configuration is now a package (`core/config/`) with:
- `loaders.py` - file loading and merging (global â†’ project)
- `models/` - Pydantic models for type-safe config
- Use `get_config()` singleton, never load config directly

**Handler Pattern**: Loop phases use handler classes (`core/loop/handlers/`):
- Each workflow has a dedicated handler (e.g., `CreateStoryHandler`)
- Handlers inherit from `BaseHandler` ABC
- Dispatch via `core/loop/dispatch.py`

**Atomic Writes**: State persistence uses temp file + `os.rename()` for crash resilience.

**EpicId Type**: Supports both numeric (1, 2, 3) and string ("testarch", "standalone") epic identifiers.

**Strategic Context**: Configurable document loading per workflow via `strategic_context:` in config.

### Workflow Phases (Configurable via LoopConfig)

Default sequence: CREATE_STORY â†’ VALIDATE_STORY â†’ VALIDATE_STORY_SYNTHESIS â†’ DEV_STORY â†’ CODE_REVIEW â†’ CODE_REVIEW_SYNTHESIS (â†’ RETROSPECTIVE)

Phase sequence is defined in `bmad-assist.yaml` under `loop:` key:
```yaml
loop:
  epic_setup: []                    # Before first story
  story:                            # Per-story phases
    - create_story
    - validate_story
    - validate_story_synthesis
    - dev_story
    - code_review
    - code_review_synthesis
  epic_teardown:                    # After last story
    - retrospective
```

Epic retrospective runs only after last story in epic completes.
Multi-LLM runs in parallel; only Master LLM can modify files.

### Validation Report Extraction (Multi-LLM)

Multi-LLM validators output reports to stdout (no file writes). The orchestrator extracts report content using markers:

```
<!-- VALIDATION_REPORT_START -->
# Story Context Validation Report
...report content...
<!-- VALIDATION_REPORT_END -->
```

**Extraction strategy** (`validation/reports.py:extract_validation_report()`):
1. **Primary**: Extract between markers
2. **Fallback**: Find report header and extract to end
3. **Last resort**: Use raw output

## Code Style

- Python 3.11+, PEP8 naming (snake_case functions, PascalCase classes)
- All functions require type hints
- Google-style docstrings for public APIs
- Custom exceptions inherit from `BmadAssistError`
- Each module uses `logger = logging.getLogger(__name__)`

## Configuration

- Global config: `~/.bmad-assist/config.yaml`
- Project config: `./bmad-assist.yaml` (overrides global)
- BMAD module config: `_bmad/bmm/config.yaml`

**Provider Config Fields:**
```yaml
providers:
  master:
    provider: claude-subprocess   # Provider identifier
    model: opus                   # Model for CLI invocation
    model_name: glm-4.7           # (optional) Display name in logs/reports
    settings: ~/.claude/glm.json  # (optional) --settings flag path
  multi:
    - provider: gemini
      model: gemini-2.5-flash
```

**Benchmarking Config:**
```yaml
benchmarking:
  enabled: true                    # Enable metrics collection (default: true)
  extraction_provider: claude      # Provider for LLM extraction
  extraction_model: haiku          # Model for LLM extraction
```

**Timeouts Config:**
```yaml
# Per-phase timeout configuration (optional, overrides legacy 'timeout' field)
timeouts:
  default: 3600                    # Default timeout for all phases (seconds)
  validate_story: 600              # Shorter timeout for validation
  code_review: 900                 # Shorter timeout for code review
  # Other phases: create_story, validate_story_synthesis, dev_story,
  #               code_review_synthesis, retrospective
```

If `timeouts` section is not present, falls back to legacy `timeout` field (default: 300s).

**Notifications Config:**
```yaml
notifications:
  discord:
    webhook_url: "https://discord.com/api/webhooks/..."
    enabled: true
  telegram:
    bot_token: "..."
    chat_id: "..."
    enabled: false
```

**Strategic Context Config:**
```yaml
strategic_context:
  project_context: true    # Always include project-context.md
  prd: auto               # Include for create_story, dev_story
  architecture: auto      # Include for dev_story, code_review
  ux: false               # Include UX docs
```

### Master LLM Timing Tracking

Timing is automatically tracked for `create-story` and `dev-story` workflows when `benchmarking.enabled: true`.

**File pattern:**
```
_bmad-output/implementation-artifacts/benchmarks/YYYY-MM/eval-{epic}-{story}-master-{timestamp}.yaml
```

**Enabled handlers:**
- `CreateStoryHandler` â†’ `timing_workflow_id = "create-story"`
- `DevStoryHandler` â†’ `timing_workflow_id = "dev-story"`

## Project Documentation

- `docs/prd.md` - 62 functional + 13 non-functional requirements
- `docs/architecture.md` - Full architectural decisions and patterns
- `docs/project-context.md` - AI agent implementation rules
- `docs/epics/` - 19 epics (sharded), 120+ stories completed
- `docs/modules/testarch/` - Test Architect module documentation
- `docs/modules/dashboard/` - Dashboard module (PRD, architecture, wireframes)
- `docs/experiments/` - Experiment framework documentation (Quick start, templates, comparison)
- `_bmad-output/implementation-artifacts/sprint-status.yaml` - Current sprint tracking (testarch+)
- `docs/sprint-artifacts/sprint-status.yaml` - Legacy tracking (Epics 1-14, frozen)

## BMAD Workflow Commands

The project uses BMAD v6 for its own development:

```bash
/bmad:bmm:workflows:sprint-status      # Check current sprint
/bmad:bmm:workflows:create-story       # Create next story
/bmad:bmm:workflows:dev-story          # Implement story
/bmad:bmm:workflows:code-review        # Review implementation
```

Story lifecycle: `backlog â†’ ready-for-dev â†’ in-progress â†’ review â†’ done`

## CRITICAL: Claude Code Token Limits

**Claude Code has a hard limit of 25,000 tokens per file read.** Exceeding this crashes the session and loses all work.

### Rules to Avoid Crashes

1. **DO NOT use background shells** (`run_in_background`) for long-running processes
   - Server logs (uvicorn, etc.) can grow quickly beyond 25K tokens
   - Use foreground execution with `timeout` instead: `timeout 30 command &`

2. **DO NOT read entire outputs** from TaskOutput or large files
   - If output might be large, use `tail -100` or `head -100` via Bash
   - Never use Read tool on files > 20K tokens without offset/limit

3. **Chunking large files:**
   - Use `offset` and `limit` parameters for Read tool
   - Example: `Read file_path=X offset=0 limit=500` then `offset=500 limit=500`

4. **Safe patterns for E2E tests:**
   ```bash
   # GOOD: Foreground with timeout, capture limited output
   timeout 30 .venv/bin/bmad-assist serve --port $PORT > /tmp/server.log 2>&1 &
   SERVE_PID=$!
   sleep 3
   # ... run tests ...
   kill $SERVE_PID 2>/dev/null
   tail -50 /tmp/server.log  # Only read last 50 lines if needed

   # BAD: Background shell (output file can overflow 25K tokens)
   # Bash with run_in_background=true â†’ AVOID
   ```

5. **Output truncation:**
   - Truncate stdout/stderr in results to 8000 chars max (enough for full stack traces)
   - Don't try to read entire log files - extract only what you need
